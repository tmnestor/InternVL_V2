# Lightweight configuration for memory-constrained environments
seed: 42
deterministic: true
debug: false
log_level: info

# Data configuration - reduced for faster processing
data:
  image_size: 224  # Reduced from 448 to save memory
  batch_size: 1    # Smaller batch size to reduce memory usage
  num_workers: 1   # Fewer workers to reduce CPU usage
  augmentation: false  # Disable augmentation for faster processing
  class_distribution: [0.3, 0.3, 0.4]  # Distribution for 0, 1, 2+ receipts
  train_csv: datasets/synthetic_receipts/metadata.csv
  train_dir: datasets/synthetic_receipts/images
  val_csv: datasets/synthetic_receipts/metadata.csv
  val_dir: datasets/synthetic_receipts/images
  test_csv: datasets/synthetic_receipts/metadata.csv
  test_dir: datasets/synthetic_receipts/images

# Model configuration - simplified architecture
model:
  name: "internvl2"
  # Absolute path to the pre-downloaded model
  pretrained_path: "/home/jovyan/nfs_share/tod/InternVL2_5-1B"  # Update to your path
  use_8bit: false  # Disable 8-bit quantization to avoid issues
  classifier:
    hidden_dims: [512, 256]  # Simplified MLP with fewer neurons
    dropout_rates: [0.3, 0.2]
    batch_norm: true
    activation: "relu"  # Switched to ReLU for efficiency
  num_classes: 3  # 0, 1, or 2+ receipts

# Training configuration - simplified training regimen
training:
  epochs: 2  # Reduced epochs for faster completion
  early_stopping:
    patience: 1
    min_delta: 0.01  # Less strict improvement threshold
  optimizer:
    name: "adam"  # Standard Adam instead of AdamW
    learning_rate: 1e-4
    backbone_lr_multiplier: 0.1
    weight_decay: 0.001  # Reduced regularization
    gradient_clip: 1.0
  scheduler:
    name: "step"  # Simpler scheduler
    step_size: 1
    gamma: 0.5
  loss:
    name: "cross_entropy"
    label_smoothing: 0.05  # Reduced smoothing
  mixed_precision: false  # Disable mixed precision if causing issues
  three_stage:
    enabled: false  # Disable three-stage training for simplicity
    mlp_warmup_epochs: 1
    vision_tuning_epochs: 1

# Evaluation configuration - minimal evaluation
evaluation:
  metrics: ["accuracy"]  # Only calculate accuracy
  confusion_matrix: false
  class_report: true
  visualization: false  # Disable visualization to save memory
  calibration: false
  samples_to_visualize: 5

# Output configuration - less frequent saving
output:
  model_dir: "saved_models"
  log_dir: "logs"
  results_dir: "results"
  tensorboard: false  # Disable TensorBoard to save resources
  checkpoint_frequency: 2  # Only save at end of training
  save_best_only: true