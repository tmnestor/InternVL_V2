data:
  augmentation: true
  batch_size: 2
  image_size: 448
  max_text_length: 128
  num_workers: 1
  root_dir: data/multimodal
evaluation:
  batch_size: 16
  metrics:
    accuracy: true
    bleu: true
    f1: true
    perplexity: false
    precision: true
    recall: true
    rouge: true
  model_path: models/unified_multimodal/best_model.pt
  save_predictions: true
log_level: INFO
model:
  classifier:
    activation: gelu
    batch_norm: true
    dropout_rates:
    - 0.2
    - 0.1
    hidden_dims:
    - 512
    - 256
  multimodal: true
  num_classes: 3
  pretrained_path: /Users/tod/PretrainedLLM/InternVL2_5-1B
  use_8bit: false
output:
  checkpoint_frequency: 0
  log_dir: logs/unified_multimodal
  model_dir: models/unified_multimodal
  results_dir: results/unified_multimodal
  save_best_only: true
  save_frequency: 0
  tensorboard: false
seed: 42
training:
  early_stopping:
    min_delta: 0.01
    patience: 3
  epochs: 15
  flash_attention: false
  fp16: false
  gradient_accumulation_steps: 8
  gradient_clip: 1.0
  learning_rate: 5.0e-05
  loss_weights:
    classification: 1.0
    language: 1.0
  low_cpu_mem_usage: true
  memory_efficient: true
  optimizer:
    backbone_lr_multiplier: 0.05
    language_lr_multiplier: 0.2
    learning_rate: 5.0e-05
    name: adamw
    weight_decay: 0.01
  scheduler:
    min_lr_factor: 0.01
    name: cosine
    warmup_steps: 200
  three_stage:
    enabled: true
    stage2:
      lr_multiplier: 0.05
      start_epoch: 4
    stage3:
      lr_multiplier: 0.05
      start_epoch: 8
  torch_compile: false
  warmup_steps: 200
  weight_decay: 0.0001
